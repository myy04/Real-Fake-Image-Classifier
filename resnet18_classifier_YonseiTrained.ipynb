{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyN1SOMDwXMFEUWquIiZlL8b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myy04/Real-Fake-Image-Classifier/blob/main/resnet18_classifier_YonseiTrained.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from transformers import AutoModel, AutoProcessor\n",
        "import os\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch import Tensor\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "3IUY1CI9NU5R"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"ciplab/real-and-fake-face-detection\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLGDUZmyNV9_",
        "outputId": "0c4e0e41-a61f-4365-e469-e727d7feddcf"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/ciplab/real-and-fake-face-detection/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "qXqm7gYbNP30"
      },
      "outputs": [],
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, path):\n",
        "\n",
        "        real_images_directory = os.path.join(path, 'training_real')\n",
        "        fake_images_directory = os.path.join(path, 'training_fake')\n",
        "\n",
        "        real_images = []\n",
        "        fake_images = []\n",
        "\n",
        "        for file in os.listdir(real_images_directory):\n",
        "            real_images.append(os.path.join(real_images_directory, file))\n",
        "\n",
        "        for file in os.listdir(fake_images_directory):\n",
        "            fake_images.append(os.path.join(fake_images_directory, file))\n",
        "\n",
        "        self.images = []\n",
        "        for i in range(min(len(real_images), len(fake_images))):\n",
        "            self.images.append((real_images[i], torch.tensor([1, 0], dtype = torch.float32)))\n",
        "            self.images.append((fake_images[i], torch.tensor([0, 1], dtype = torch.float32)))\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),  # Resize to a standard size for ResNet\n",
        "            transforms.ToTensor(),          # Convert PIL Image to PyTorch Tensor\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.images[idx][0]\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        image = self.transform(image)\n",
        "\n",
        "        return image, self.images[idx][1]\n",
        "\n",
        "\n",
        "BATCHSIZE = 512\n",
        "NEPOCH = 20\n",
        "\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "train_dataset = ImageDataset(os.path.join(path, 'real_and_fake_face'))\n",
        "\n",
        "# Split the data\n",
        "train_size = int(0.8 * len(train_dataset))  # 80% for training\n",
        "eval_size = len(train_dataset) - train_size  # Remaining 20% for evaluation\n",
        "train_dataset, eval_dataset = random_split(train_dataset, [train_size, eval_size])\n",
        "\n",
        "# Create DataLoaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = BATCHSIZE, shuffle = True)\n",
        "eval_dataloader = DataLoader(eval_dataset, batch_size = BATCHSIZE, shuffle = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model = torchvision.models.resnet18(pretrained = True)\n",
        "resnet_model.fc = nn.Linear(resnet_model.fc.in_features, 2)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "resnet_model = resnet_model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(resnet_model.parameters(), lr = 1e-3)"
      ],
      "metadata": {
        "id": "ccLXyyrgPN8h"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(input: Tensor, label: Tensor):\n",
        "  resnet_model.train()\n",
        "\n",
        "  input = input.to(device)\n",
        "  label = label.to(device)\n",
        "\n",
        "  output = resnet_model(input)\n",
        "  loss = criterion(output, label)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "\n",
        "  torch.nn.utils.clip_grad_norm_(resnet_model.parameters(), max_norm=1.0)\n",
        "  optimizer.step()\n",
        "\n",
        "  return loss, output"
      ],
      "metadata": {
        "id": "dYt25C0bPSJ1"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def test_step(input: Tensor, label: Tensor):\n",
        "\n",
        "    resnet_model.eval()\n",
        "\n",
        "    input = input.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    output = resnet_model(input)\n",
        "\n",
        "    loss = criterion(output, label)\n",
        "\n",
        "    return loss, output"
      ],
      "metadata": {
        "id": "IOc9JJupVjBs"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(dataloader):\n",
        "    correct = 0\n",
        "    samples = 0\n",
        "\n",
        "    for i, (input, label) in enumerate(dataloader):\n",
        "        loss, output = train_step(input, label)\n",
        "\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "        samples += label.size(0)\n",
        "        # The label tensor has shape (batch_size, 2) - we need to compare predicted to the index with the maximum value in the label tensor\n",
        "        correct += (predicted == torch.argmax(label, dim=1).to(device)).sum().item()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Loss [{i}/{len(dataloader)}]: {loss.item()}\")\n",
        "\n",
        "    print(f\"Train Accuracy: {correct / samples * 100.00}%\")"
      ],
      "metadata": {
        "id": "cwWKC0a2VkeP"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_epoch(dataloader):\n",
        "    correct = 0\n",
        "    samples = 0\n",
        "\n",
        "    for i, (input, label) in enumerate(dataloader):\n",
        "        loss, output = test_step(input, label)\n",
        "\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "        samples += label.size(0)\n",
        "        correct += (predicted == torch.argmax(label, dim=1).to(device)).sum().item()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Loss [{i}/{len(dataloader)}]: {loss.item()}\")\n",
        "\n",
        "    print(f\"Test Accuracy: {correct / samples * 100.00}%\")"
      ],
      "metadata": {
        "id": "tmmrVZv3VmGo"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(NEPOCH):\n",
        "    train_epoch(train_dataloader)\n",
        "\n",
        "    test_epoch(eval_dataloader)\n",
        "\n",
        "torch.save(resnet_model.state_dict(), 'resnet_model_parameters.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2IRtiAIVnzk",
        "outputId": "8ca59c59-992e-48d2-9d1a-e9e172ea2f61"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss [0/3]: 0.7435621023178101\n",
            "Train Accuracy: 50.651041666666664%\n",
            "Loss [0/1]: 0.7256205081939697\n",
            "Test Accuracy: 52.604166666666664%\n",
            "Loss [0/3]: 0.7376407384872437\n",
            "Train Accuracy: 50.520833333333336%\n",
            "Loss [0/1]: 0.7083730101585388\n",
            "Test Accuracy: 54.947916666666664%\n",
            "Loss [0/3]: 0.7158883213996887\n",
            "Train Accuracy: 50.520833333333336%\n",
            "Loss [0/1]: 0.6953555941581726\n",
            "Test Accuracy: 54.427083333333336%\n",
            "Loss [0/3]: 0.7277482748031616\n",
            "Train Accuracy: 50.651041666666664%\n",
            "Loss [0/1]: 0.688300609588623\n",
            "Test Accuracy: 55.46875%\n",
            "Loss [0/3]: 0.7332004308700562\n",
            "Train Accuracy: 51.302083333333336%\n",
            "Loss [0/1]: 0.6855652332305908\n",
            "Test Accuracy: 55.989583333333336%\n",
            "Loss [0/3]: 0.7099263668060303\n",
            "Train Accuracy: 51.236979166666664%\n",
            "Loss [0/1]: 0.6850180625915527\n",
            "Test Accuracy: 55.989583333333336%\n",
            "Loss [0/3]: 0.7206705808639526\n",
            "Train Accuracy: 52.1484375%\n",
            "Loss [0/1]: 0.6851096153259277\n",
            "Test Accuracy: 55.46875%\n",
            "Loss [0/3]: 0.717328667640686\n",
            "Train Accuracy: 52.213541666666664%\n",
            "Loss [0/1]: 0.6850537061691284\n",
            "Test Accuracy: 55.729166666666664%\n",
            "Loss [0/3]: 0.7104937434196472\n",
            "Train Accuracy: 52.994791666666664%\n",
            "Loss [0/1]: 0.6850549578666687\n",
            "Test Accuracy: 54.947916666666664%\n",
            "Loss [0/3]: 0.7229154109954834\n",
            "Train Accuracy: 52.799479166666664%\n",
            "Loss [0/1]: 0.6850160360336304\n",
            "Test Accuracy: 54.947916666666664%\n",
            "Loss [0/3]: 0.7261718511581421\n",
            "Train Accuracy: 53.7109375%\n",
            "Loss [0/1]: 0.6847267150878906\n",
            "Test Accuracy: 55.208333333333336%\n",
            "Loss [0/3]: 0.7029222249984741\n",
            "Train Accuracy: 52.9296875%\n",
            "Loss [0/1]: 0.6843161582946777\n",
            "Test Accuracy: 55.208333333333336%\n",
            "Loss [0/3]: 0.7181233763694763\n",
            "Train Accuracy: 53.776041666666664%\n",
            "Loss [0/1]: 0.6838745474815369\n",
            "Test Accuracy: 54.947916666666664%\n",
            "Loss [0/3]: 0.7019112706184387\n",
            "Train Accuracy: 54.361979166666664%\n",
            "Loss [0/1]: 0.6833867430686951\n",
            "Test Accuracy: 55.208333333333336%\n",
            "Loss [0/3]: 0.7181538939476013\n",
            "Train Accuracy: 53.971354166666664%\n",
            "Loss [0/1]: 0.6827367544174194\n",
            "Test Accuracy: 55.208333333333336%\n",
            "Loss [0/3]: 0.6966959238052368\n",
            "Train Accuracy: 54.1015625%\n",
            "Loss [0/1]: 0.6820532083511353\n",
            "Test Accuracy: 56.25%\n",
            "Loss [0/3]: 0.7002881765365601\n",
            "Train Accuracy: 54.622395833333336%\n",
            "Loss [0/1]: 0.6813898086547852\n",
            "Test Accuracy: 55.989583333333336%\n",
            "Loss [0/3]: 0.7003605365753174\n",
            "Train Accuracy: 55.729166666666664%\n",
            "Loss [0/1]: 0.6806699633598328\n",
            "Test Accuracy: 56.25%\n",
            "Loss [0/3]: 0.6814910769462585\n",
            "Train Accuracy: 55.533854166666664%\n",
            "Loss [0/1]: 0.6800737380981445\n",
            "Test Accuracy: 56.510416666666664%\n",
            "Loss [0/3]: 0.6936924457550049\n",
            "Train Accuracy: 55.2734375%\n",
            "Loss [0/1]: 0.6792857646942139\n",
            "Test Accuracy: 56.770833333333336%\n"
          ]
        }
      ]
    }
  ]
}