{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyNviImNQt7Z7Kkgzsdhjbgl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myy04/Real-Fake-Image-Classifier/blob/main/CLIP_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Tz9wdJjiMBlJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from transformers import AutoModel, AutoProcessor\n",
        "import os\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch import Tensor\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"birdy654/cifake-real-and-ai-generated-synthetic-images\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDOWntFAMEmk",
        "outputId": "fcb0bd83-a196-4f9c-c946-0ac884db9e1c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.5)\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/birdy654/cifake-real-and-ai-generated-synthetic-images/versions/3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, path):\n",
        "\n",
        "        real_images_directory = os.path.join(path, 'REAL')\n",
        "        fake_images_directory = os.path.join(path, 'FAKE')\n",
        "\n",
        "        real_images = []\n",
        "        fake_images = []\n",
        "\n",
        "        for file in os.listdir(real_images_directory):\n",
        "            real_images.append(os.path.join(real_images_directory, file))\n",
        "\n",
        "        for file in os.listdir(fake_images_directory):\n",
        "            fake_images.append(os.path.join(fake_images_directory, file))\n",
        "\n",
        "        self.images = []\n",
        "        for i in range(min(len(real_images), len(fake_images))):\n",
        "            self.images.append((real_images[i], torch.tensor([1, 0], dtype = torch.float32)))\n",
        "            self.images.append((fake_images[i], torch.tensor([0, 1], dtype = torch.float32)))\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.images[idx][0]\n",
        "\n",
        "        return Image.open(image_path), self.images[idx][1]\n",
        "\n",
        "\n",
        "\n",
        "eval_dataset = ImageDataset(os.path.join(path, 'test'))\n",
        "\n"
      ],
      "metadata": {
        "id": "uizooHiOMGFy"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "clip_processor = AutoProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "model = AutoModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "num_of_correct = 0\n",
        "total = 0\n",
        "\n",
        "import random\n",
        "\n",
        "for timer in range(0, 1000):\n",
        "  i = random.randint(0, len(eval_dataset) - 1)\n",
        "\n",
        "  image, label = eval_dataset.__getitem__(i)\n",
        "\n",
        "  inputs = clip_processor(text = ['real', 'fake'], images=image, return_tensors=\"pt\", padding = True)\n",
        "  outputs = model(**inputs)\n",
        "\n",
        "  logits_per_image = outputs.logits_per_image # this is the image-text similarity score\n",
        "  probs = logits_per_image.softmax(dim=1) # we can take the softmax to get the label probabilities\n",
        "\n",
        "  predicted_class = torch.argmax(probs, dim=1)\n",
        "  correct_prediction = torch.eq(predicted_class, torch.argmax(label, dim = 0))  # Check if prediction matches target\n",
        "\n",
        "  total += 1\n",
        "  if correct_prediction:\n",
        "    num_of_correct += 1\n",
        "\n",
        "print(f'Accuracy: {num_of_correct / total * 100}')\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvGjDFpJMjEM",
        "outputId": "349f2714-dbce-437c-c044-8443541a6b9d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 50.7\n"
          ]
        }
      ]
    }
  ]
}