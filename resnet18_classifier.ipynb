{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyP0g9EVmUu7D+byCEPsJkhm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myy04/Real-Fake-Image-Classifier/blob/main/resnet18_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from transformers import AutoModel, AutoProcessor\n",
        "import os\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch import Tensor\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "3IUY1CI9NU5R"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"birdy654/cifake-real-and-ai-generated-synthetic-images\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLGDUZmyNV9_",
        "outputId": "cd03f6c0-b347-4963-e58a-2e87b7597e01"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.5)\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/birdy654/cifake-real-and-ai-generated-synthetic-images/versions/3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "qXqm7gYbNP30"
      },
      "outputs": [],
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, path):\n",
        "\n",
        "        real_images_directory = os.path.join(path, 'REAL')\n",
        "        fake_images_directory = os.path.join(path, 'FAKE')\n",
        "\n",
        "        real_images = []\n",
        "        fake_images = []\n",
        "\n",
        "        for file in os.listdir(real_images_directory):\n",
        "            real_images.append(os.path.join(real_images_directory, file))\n",
        "\n",
        "        for file in os.listdir(fake_images_directory):\n",
        "            fake_images.append(os.path.join(fake_images_directory, file))\n",
        "\n",
        "        self.images = []\n",
        "        for i in range(min(len(real_images), len(fake_images))):\n",
        "            self.images.append((real_images[i], torch.tensor([1, 0], dtype = torch.float32)))\n",
        "            self.images.append((fake_images[i], torch.tensor([0, 1], dtype = torch.float32)))\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),  # Resize to a standard size for ResNet\n",
        "            transforms.ToTensor(),          # Convert PIL Image to PyTorch Tensor\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.images[idx][0]\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        image = self.transform(image)\n",
        "\n",
        "        return image, self.images[idx][1]\n",
        "\n",
        "\n",
        "BATCHSIZE = 128\n",
        "NEPOCH = 20\n",
        "\n",
        "train_dataset = ImageDataset(os.path.join(path, 'train'))\n",
        "eval_dataset = ImageDataset(os.path.join(path, 'test'))\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = BATCHSIZE, shuffle = True)\n",
        "eval_dataloader = DataLoader(eval_dataset, batch_size = BATCHSIZE, shuffle = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model = torchvision.models.resnet18(pretrained = False)\n",
        "resnet_model.fc = nn.Linear(resnet_model.fc.in_features, 2)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "resnet_model = resnet_model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(resnet_model.parameters(), weight_decay=1e-3)"
      ],
      "metadata": {
        "id": "ccLXyyrgPN8h"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(input: Tensor, label: Tensor):\n",
        "  resnet_model.train()\n",
        "\n",
        "  input = input.to(device)\n",
        "  label = label.to(device)\n",
        "\n",
        "  output = resnet_model(input)\n",
        "  loss = criterion(output, label)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "\n",
        "  torch.nn.utils.clip_grad_norm_(resnet_model.parameters(), max_norm=1.0)\n",
        "  optimizer.step()\n",
        "\n",
        "  return loss, output"
      ],
      "metadata": {
        "id": "dYt25C0bPSJ1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def test_step(input: Tensor, label: Tensor):\n",
        "\n",
        "    resnet_model.eval()\n",
        "\n",
        "    input = input.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    output = resnet_model(input)\n",
        "\n",
        "    loss = criterion(output, label)\n",
        "\n",
        "    return loss, output"
      ],
      "metadata": {
        "id": "IOc9JJupVjBs"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(dataloader):\n",
        "    correct = 0\n",
        "    samples = 0\n",
        "\n",
        "    for i, (input, label) in enumerate(dataloader):\n",
        "        loss, output = train_step(input, label)\n",
        "\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "        samples += label.size(0)\n",
        "        # The label tensor has shape (batch_size, 2) - we need to compare predicted to the index with the maximum value in the label tensor\n",
        "        correct += (predicted == torch.argmax(label, dim=1).to(device)).sum().item()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Loss [{i}/{len(dataloader)}]: {loss.item()}\")\n",
        "\n",
        "    print(f\"Train Accuracy: {correct / samples * 100.00}%\")"
      ],
      "metadata": {
        "id": "cwWKC0a2VkeP"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_epoch(dataloader):\n",
        "    correct = 0\n",
        "    samples = 0\n",
        "\n",
        "    for i, (input, label) in enumerate(dataloader):\n",
        "        loss, output = test_step(input, label)\n",
        "\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "        samples += label.size(0)\n",
        "        correct += (predicted == torch.argmax(label, dim=1).to(device)).sum().item()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Loss [{i}/{len(dataloader)}]: {loss.item()}\")\n",
        "\n",
        "    print(f\"Test Accuracy: {correct / samples * 100.00}%\")"
      ],
      "metadata": {
        "id": "tmmrVZv3VmGo"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(NEPOCH):\n",
        "    train_epoch(train_dataloader)\n",
        "\n",
        "    test_epoch(eval_dataloader)\n",
        "\n",
        "torch.save(resnet_model.state_dict(), 'resnet_model_parameters.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2IRtiAIVnzk",
        "outputId": "ad58598e-c445-4dff-d147-ae57fca13b53"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss [0/782]: 0.7163615226745605\n",
            "Loss [100/782]: 0.6752097606658936\n",
            "Loss [200/782]: 0.6483266353607178\n",
            "Loss [300/782]: 0.6146159768104553\n",
            "Loss [400/782]: 0.6170250177383423\n",
            "Loss [500/782]: 0.550330638885498\n",
            "Loss [600/782]: 0.5632714033126831\n",
            "Loss [700/782]: 0.5873779058456421\n",
            "Train Accuracy: 70.282%\n",
            "Loss [0/157]: 0.5433982610702515\n",
            "Loss [100/157]: 0.5646390914916992\n",
            "Test Accuracy: 75.84%\n",
            "Loss [0/782]: 0.5585246086120605\n",
            "Loss [100/782]: 0.5091971158981323\n",
            "Loss [200/782]: 0.5622423887252808\n",
            "Loss [300/782]: 0.491061270236969\n",
            "Loss [400/782]: 0.4896157681941986\n",
            "Loss [500/782]: 0.4443996846675873\n",
            "Loss [600/782]: 0.4582618176937103\n",
            "Loss [700/782]: 0.4932329058647156\n",
            "Train Accuracy: 77.73%\n",
            "Loss [0/157]: 0.4603258967399597\n",
            "Loss [100/157]: 0.49428486824035645\n",
            "Test Accuracy: 79.66%\n",
            "Loss [0/782]: 0.4920300841331482\n",
            "Loss [100/782]: 0.4918546676635742\n",
            "Loss [200/782]: 0.4115431010723114\n",
            "Loss [300/782]: 0.4064381718635559\n",
            "Loss [400/782]: 0.48792868852615356\n",
            "Loss [500/782]: 0.4037911295890808\n",
            "Loss [600/782]: 0.4871499538421631\n",
            "Loss [700/782]: 0.44339263439178467\n",
            "Train Accuracy: 80.655%\n",
            "Loss [0/157]: 0.46849191188812256\n",
            "Loss [100/157]: 0.4519742727279663\n",
            "Test Accuracy: 81.39%\n",
            "Loss [0/782]: 0.4378657639026642\n",
            "Loss [100/782]: 0.40349432826042175\n",
            "Loss [200/782]: 0.4309758245944977\n",
            "Loss [300/782]: 0.4288586378097534\n",
            "Loss [400/782]: 0.47841495275497437\n",
            "Loss [500/782]: 0.4199593663215637\n",
            "Loss [600/782]: 0.3425709903240204\n",
            "Loss [700/782]: 0.4512005150318146\n",
            "Train Accuracy: 82.03%\n",
            "Loss [0/157]: 0.3789016008377075\n",
            "Loss [100/157]: 0.445313036441803\n",
            "Test Accuracy: 82.78%\n",
            "Loss [0/782]: 0.4023467004299164\n",
            "Loss [100/782]: 0.3777979612350464\n",
            "Loss [200/782]: 0.3203326165676117\n",
            "Loss [300/782]: 0.37718909978866577\n",
            "Loss [400/782]: 0.36716949939727783\n",
            "Loss [500/782]: 0.37857747077941895\n",
            "Loss [600/782]: 0.46281230449676514\n",
            "Loss [700/782]: 0.3980238735675812\n",
            "Train Accuracy: 83.196%\n",
            "Loss [0/157]: 0.3522759675979614\n",
            "Loss [100/157]: 0.33893436193466187\n",
            "Test Accuracy: 83.555%\n",
            "Loss [0/782]: 0.34296154975891113\n",
            "Loss [100/782]: 0.34327369928359985\n",
            "Loss [200/782]: 0.46860647201538086\n",
            "Loss [300/782]: 0.3484570384025574\n",
            "Loss [400/782]: 0.3844759464263916\n",
            "Loss [500/782]: 0.35994210839271545\n",
            "Loss [600/782]: 0.27209627628326416\n",
            "Loss [700/782]: 0.3811725974082947\n",
            "Train Accuracy: 84.03699999999999%\n",
            "Loss [0/157]: 0.31904447078704834\n",
            "Loss [100/157]: 0.32099565863609314\n",
            "Test Accuracy: 84.175%\n",
            "Loss [0/782]: 0.39090216159820557\n",
            "Loss [100/782]: 0.45988547801971436\n",
            "Loss [200/782]: 0.282961905002594\n",
            "Loss [300/782]: 0.4505886137485504\n",
            "Loss [400/782]: 0.33259862661361694\n",
            "Loss [500/782]: 0.28886789083480835\n",
            "Loss [600/782]: 0.32665422558784485\n",
            "Loss [700/782]: 0.3348905146121979\n",
            "Train Accuracy: 84.78%\n",
            "Loss [0/157]: 0.3104712963104248\n",
            "Loss [100/157]: 0.40933865308761597\n",
            "Test Accuracy: 85.015%\n",
            "Loss [0/782]: 0.36686691641807556\n",
            "Loss [100/782]: 0.37799182534217834\n",
            "Loss [200/782]: 0.3485613167285919\n",
            "Loss [300/782]: 0.385393351316452\n",
            "Loss [400/782]: 0.3026694357395172\n",
            "Loss [500/782]: 0.40712904930114746\n",
            "Loss [600/782]: 0.4426952004432678\n",
            "Loss [700/782]: 0.3282005190849304\n",
            "Train Accuracy: 85.456%\n",
            "Loss [0/157]: 0.32576870918273926\n",
            "Loss [100/157]: 0.37180933356285095\n",
            "Test Accuracy: 85.64500000000001%\n",
            "Loss [0/782]: 0.4328082203865051\n",
            "Loss [100/782]: 0.350070595741272\n",
            "Loss [200/782]: 0.34181445837020874\n",
            "Loss [300/782]: 0.31258222460746765\n",
            "Loss [400/782]: 0.3710940182209015\n",
            "Loss [500/782]: 0.31768742203712463\n",
            "Loss [600/782]: 0.3191972076892853\n",
            "Loss [700/782]: 0.3244156837463379\n",
            "Train Accuracy: 85.827%\n",
            "Loss [0/157]: 0.2777872681617737\n",
            "Loss [100/157]: 0.29659634828567505\n",
            "Test Accuracy: 86.095%\n",
            "Loss [0/782]: 0.3164913058280945\n",
            "Loss [100/782]: 0.2836887836456299\n",
            "Loss [200/782]: 0.36040738224983215\n",
            "Loss [300/782]: 0.38912081718444824\n",
            "Loss [400/782]: 0.34969717264175415\n",
            "Loss [500/782]: 0.30227816104888916\n",
            "Loss [600/782]: 0.30866867303848267\n",
            "Loss [700/782]: 0.3287476897239685\n",
            "Train Accuracy: 86.31299999999999%\n",
            "Loss [0/157]: 0.38447105884552\n",
            "Loss [100/157]: 0.3035481572151184\n",
            "Test Accuracy: 86.33999999999999%\n",
            "Loss [0/782]: 0.30269303917884827\n",
            "Loss [100/782]: 0.22342443466186523\n",
            "Loss [200/782]: 0.2878011465072632\n",
            "Loss [300/782]: 0.27138853073120117\n",
            "Loss [400/782]: 0.2981579899787903\n",
            "Loss [500/782]: 0.29517054557800293\n",
            "Loss [600/782]: 0.33889561891555786\n",
            "Loss [700/782]: 0.29236385226249695\n",
            "Train Accuracy: 86.803%\n",
            "Loss [0/157]: 0.4133736491203308\n",
            "Loss [100/157]: 0.30571725964546204\n",
            "Test Accuracy: 86.47500000000001%\n",
            "Loss [0/782]: 0.2753634452819824\n",
            "Loss [100/782]: 0.24454092979431152\n",
            "Loss [200/782]: 0.2061099112033844\n",
            "Loss [300/782]: 0.2739725112915039\n",
            "Loss [400/782]: 0.2362983524799347\n",
            "Loss [500/782]: 0.369546115398407\n",
            "Loss [600/782]: 0.28878408670425415\n",
            "Loss [700/782]: 0.2833060026168823\n",
            "Train Accuracy: 87.019%\n",
            "Loss [0/157]: 0.2835528254508972\n",
            "Loss [100/157]: 0.32937827706336975\n",
            "Test Accuracy: 87.175%\n",
            "Loss [0/782]: 0.34709233045578003\n",
            "Loss [100/782]: 0.3053615093231201\n",
            "Loss [200/782]: 0.30365386605262756\n",
            "Loss [300/782]: 0.3597800135612488\n",
            "Loss [400/782]: 0.28846681118011475\n",
            "Loss [500/782]: 0.37285786867141724\n",
            "Loss [600/782]: 0.38099515438079834\n",
            "Loss [700/782]: 0.25453734397888184\n",
            "Train Accuracy: 87.348%\n",
            "Loss [0/157]: 0.22340616583824158\n",
            "Loss [100/157]: 0.35603538155555725\n",
            "Test Accuracy: 87.325%\n",
            "Loss [0/782]: 0.35180360078811646\n",
            "Loss [100/782]: 0.25407207012176514\n",
            "Loss [200/782]: 0.3937283158302307\n",
            "Loss [300/782]: 0.29661041498184204\n",
            "Loss [400/782]: 0.33782580494880676\n",
            "Loss [500/782]: 0.34175926446914673\n",
            "Loss [600/782]: 0.2396915704011917\n",
            "Loss [700/782]: 0.39591172337532043\n",
            "Train Accuracy: 87.529%\n",
            "Loss [0/157]: 0.1975354552268982\n",
            "Loss [100/157]: 0.28451770544052124\n",
            "Test Accuracy: 87.79%\n",
            "Loss [0/782]: 0.2589656114578247\n",
            "Loss [100/782]: 0.24733185768127441\n",
            "Loss [200/782]: 0.3101441562175751\n",
            "Loss [300/782]: 0.23828110098838806\n",
            "Loss [400/782]: 0.29661816358566284\n",
            "Loss [500/782]: 0.24996596574783325\n",
            "Loss [600/782]: 0.36757439374923706\n",
            "Loss [700/782]: 0.31237685680389404\n",
            "Train Accuracy: 87.87899999999999%\n",
            "Loss [0/157]: 0.30866533517837524\n",
            "Loss [100/157]: 0.27883148193359375\n",
            "Test Accuracy: 87.85%\n",
            "Loss [0/782]: 0.32361048460006714\n",
            "Loss [100/782]: 0.36098819971084595\n",
            "Loss [200/782]: 0.2938515245914459\n",
            "Loss [300/782]: 0.30348074436187744\n",
            "Loss [400/782]: 0.2495063841342926\n",
            "Loss [500/782]: 0.2674485146999359\n",
            "Loss [600/782]: 0.18603909015655518\n",
            "Loss [700/782]: 0.32546722888946533\n",
            "Train Accuracy: 88.126%\n",
            "Loss [0/157]: 0.2837062180042267\n",
            "Loss [100/157]: 0.2553310990333557\n",
            "Test Accuracy: 88.29%\n",
            "Loss [0/782]: 0.28403231501579285\n",
            "Loss [100/782]: 0.21059459447860718\n",
            "Loss [200/782]: 0.24318400025367737\n",
            "Loss [300/782]: 0.2943255305290222\n",
            "Loss [400/782]: 0.320203572511673\n",
            "Loss [500/782]: 0.2653031349182129\n",
            "Loss [600/782]: 0.2562781274318695\n",
            "Loss [700/782]: 0.3358864188194275\n",
            "Train Accuracy: 88.306%\n",
            "Loss [0/157]: 0.32681289315223694\n",
            "Loss [100/157]: 0.29492080211639404\n",
            "Test Accuracy: 88.685%\n",
            "Loss [0/782]: 0.24291439354419708\n",
            "Loss [100/782]: 0.2793227434158325\n",
            "Loss [200/782]: 0.3002437353134155\n",
            "Loss [300/782]: 0.242654487490654\n",
            "Loss [400/782]: 0.3053019046783447\n",
            "Loss [500/782]: 0.241960346698761\n",
            "Loss [600/782]: 0.28147658705711365\n",
            "Loss [700/782]: 0.30677247047424316\n",
            "Train Accuracy: 88.529%\n",
            "Loss [0/157]: 0.25319698452949524\n",
            "Loss [100/157]: 0.23563529551029205\n",
            "Test Accuracy: 88.75999999999999%\n",
            "Loss [0/782]: 0.200562983751297\n",
            "Loss [100/782]: 0.261689156293869\n",
            "Loss [200/782]: 0.2589126229286194\n",
            "Loss [300/782]: 0.21551945805549622\n",
            "Loss [400/782]: 0.31607678532600403\n",
            "Loss [500/782]: 0.2643306255340576\n",
            "Loss [600/782]: 0.27527719736099243\n",
            "Loss [700/782]: 0.3324356973171234\n",
            "Train Accuracy: 88.73%\n",
            "Loss [0/157]: 0.2803983688354492\n",
            "Loss [100/157]: 0.2156660556793213\n",
            "Test Accuracy: 88.97500000000001%\n",
            "Loss [0/782]: 0.2933235168457031\n",
            "Loss [100/782]: 0.2699841260910034\n",
            "Loss [200/782]: 0.3116433024406433\n",
            "Loss [300/782]: 0.2592702805995941\n",
            "Loss [400/782]: 0.29448652267456055\n",
            "Loss [500/782]: 0.2625553011894226\n",
            "Loss [600/782]: 0.2094579041004181\n",
            "Loss [700/782]: 0.2933955192565918\n",
            "Train Accuracy: 88.882%\n",
            "Loss [0/157]: 0.29446133971214294\n",
            "Loss [100/157]: 0.25360894203186035\n",
            "Test Accuracy: 89.1%\n"
          ]
        }
      ]
    }
  ]
}